



# CH3-4

![](/home/guan/Desktop/计算机网络/Images/4.4/c0ca74a1-3834-4139-bb4c-d52d6d297ea7.png)

## 关于为什么要快速恢复

丢包后跟它一起发的包还在CWND一起等着它占着“假空间“，由于数据包守恒，回来dupACK说明有个包发过去了，可以把CWND扩一个了（拟式的），给要发的新包空间，等好了再还原回去CWND就行。

例子：

![](/home/guan/Desktop/计算机网络/Images/4.4/034e3a45-2f22-4f3c-a588-62f2beaed911.png)

## TCP状态机

![](/home/guan/Desktop/计算机网络/Images/4.4/61503ea0-7681-43f0-b32e-0bdf462c642f.png)

![](/home/guan/Desktop/计算机网络/Images/4.4/08c2491f-ea55-4efa-bcaa-941e64da882f.png)

![](/home/guan/Desktop/计算机网络/Images/4.4/a964773b-2cc5-4f3a-8770-3222b99fc2e3.png)

![](/home/guan/Desktop/计算机网络/Images/4.4/ed9ae33a-26ce-4360-93e3-47e156418b1e.png)

![](/home/guan/Desktop/计算机网络/Images/4.4/ad814b7d-aa93-4b45-ae9d-e45c52f55aed.png)

### TCP拥塞控制算法

![](/home/guan/Desktop/计算机网络/Images/4.4/c702fee4-ee95-4603-a63e-eda62d1f63d5.png)

---

## TCP吞吐量

### 最简单的模型（单纯加性增乘性减）

![](/home/guan/Desktop/计算机网络/Images/4.4/dabe603c-ab15-4b25-9dbb-83c1c2cdb402.png)

![](/home/guan/Desktop/计算机网络/Images/4.4/67a93ddd-785c-4e53-bda3-c00765e70259.png)

丢包率p:每发A个包会丢一个包,因此为1/A

吞吐量B：每s(单位时间发多少个包)，而per RTT=3/4Wmax packets=上式

- 数据流得到的吞吐量和RTT成反比
- 当网络中不同TCP连接的RTT差异较大时，TCP的资源分配会变得不公平（慢的被饿死）

![](/home/guan/Desktop/计算机网络/Images/4.4/ee18be58-55c3-4327-85de-a7f0dad68ad6.png)

Throughput=BW/MSS,第一个用吞吐量公式代入

第二个沿用第一问p,p=1/A，A=3/8W^2,dt=w/2 *RTT

第三个：data不是packet,16.6hours乘BW即可

---

### 使TCP适应高速的方法

- 一旦超过临界速度，让CWND增加更快
  - 让AIMD的加法常数依赖于CWND
- 其他方法
  - 通过非标准或临时性技术手段实现多个并发网络连接，尽管这些方法可能不够优雅或存在潜在风险，但在当前环境下仍然有效。
  - 依赖路由器或路由机制辅助管理网络连接或数据传输的技术方案，通常通过路由器的智能调度、协议优化或路径选择来提升性能、安全性或功能性。

---

### 基于速率的拥塞控制：Equation-Based Congestion Control

**Equation-Based Congestion Control（基于方程的拥塞控制）** 是一种通过数学模型动态调整数据发送速率以适配网络拥塞状态的机制。其核心目标是实现与TCP流量的公平竞争（即“TCP友好性”），同时减少速率波动，适用于实时音视频传输等对平滑性要求较高的场景。

![](/home/guan/Desktop/计算机网络/Images/4.4/bb9189cd-d268-4d99-9837-4b897bb5e9c9.png)

---

### 公式的问题

TCP默认假设**丢包均由网络拥塞引起**

#### **问题根源**：

- **误判非拥塞丢包**（如无线链路误码、物理干扰）时，TCP仍触发拥塞控制，导致**不必要的速率降低**。
- **公式适用性**：公式中 pp 包含所有丢包类型，因此在非拥塞丢包场景中，TCP性能被严重低估。

---

### 短流的定义与影响

#### **数据特征**

- **50%的流传输数据量 < 1500B**（约1个TCP报文段）。
- **80%的流 < 100KB**（约67个报文段，假设MSS=1460B）。
- **典型场景**：HTTP短请求、API调用、实时游戏指令。

#### **性能问题**

- **无法完成慢启动**：短流在进入拥塞避免阶段前已传输完毕，导致：
  - **吞吐量低下**：未充分利用带宽（cwnd未充分增长）。
  - **公平性失衡**：长流（如视频下载）持续占用拥塞避免阶段的高窗口，挤压短流。
- **丢包恢复低效**：
  - **无法触发快速重传**（需至少3个dupACK），丢包依赖超时重传（RTO≥500ms）。
  - **流完成时间（FCT）显著增加**：超时占主导，例如1%丢包率下，1500B流的FCT可能从10ms增至510ms（**50倍恶化**）。

### **长流（大文件）与短流（小文件）共享瓶颈链路时的资源竞争**

当长流（如10GB传输）与多个短流（如100B请求）共享同一瓶颈链路时，传统的TCP拥塞控制机制（如Reno）会导致**长流占据主导地位**，短流因无法快速获取带宽而经历高延迟。以下是关键原因及解决方案：

------

#### **1. 长流主导带宽的机制**

- **TCP拥塞控制特性**：
  - **慢启动（Slow Start）**：长流通过指数增长窗口迅速抢占带宽。
  - **拥塞避免（Congestion Avoidance）**：长流进入线性增长阶段后，持续占用高窗口值，挤压短流。
- **资源竞争不均衡**：
  - **长流优势**：传输时间长，窗口逐渐逼近链路容量，形成稳态占用。
  - **短流劣势**：窗口未充分增长即完成传输，无法有效竞争带宽。

**示例场景**：

- **瓶颈链路容量**：1 Gbps（假设RTT=50ms，MSS=1460B）。
- **长流（10GB）**：初始窗口10 MSS，经慢启动后窗口稳定在约800 MSS（占用90%带宽）。
- **短流（100B）**：初始窗口10 MSS，需传输约1个报文段，但需排队等待长流释放带宽。

**结果**：

- 长流吞吐量：≈900 Mbps。
- 短流排队延迟：因链路满载，每个短流需等待约 **4.5ms**（假设10个短流竞争10%带宽）。
- **短流完成时间（FCT）**：从理论上的0.05ms（无竞争）增至 **5ms+排队延迟**（恶化100倍）。

------

#### **2. 传统TCP的公平性缺陷**

- **吞吐量公式的局限性**：
  - 经典TCP吞吐量模型 Throughput∝1RTTpThroughput∝RTTp

- - 1 假设所有流长期竞争，但短流生命周期过短，无法达到公平稳态。
- **缓冲区膨胀（Bufferbloat）**：
  - 长流占用路由器缓冲，导致短流排队延迟激增（如从1ms增至100ms）。

------

### 作弊

- #### **超速增加拥塞窗口**

- #### **使用大初始窗口**

- #### **开启多个并发连接**

![](/home/guan/Desktop/计算机网络/Images/4.4/6259516f-7220-4100-9b73-3774f485d413.png)

---

## **路由器辅助的拥塞控制（Router-Assisted Congestion Control）**

![](/home/guan/Desktop/计算机网络/Images/4.4/734d716d-7a28-4523-b4ca-aeeec587580d.png)

### 技术

![](/home/guan/Desktop/计算机网络/Images/4.4/3e9b2305-2ae8-4286-9c11-872fcca39e18.png)

### 抑制分组

1. Choke Packet（抑制包）
   定义与工作原理

    功能：网络节点（如路由器或接收端）在检测到拥塞时，主动向数据源发送控制包，要求其降低发送速率。

    触发条件：

        路由器队列长度超过阈值。
       
        接收端处理能力不足（如缓冲区满）。

    工作流程：

        拥塞节点生成Choke Packet，包含源地址、目标地址及拥塞级别信息。
       
        通过控制信道（如ICMP）发送至数据源。
       
        数据源收到后，按协议规则减少拥塞窗口（cwnd）或暂停发送。

2. Source Quench（源抑制）
   定义与工作原理

    协议基础：基于ICMP协议（Internet Control Message Protocol）的反馈机制，定义于RFC 792。

    触发条件：

        路由器或接收端因拥塞丢弃数据包时，生成ICMP Source Quench消息。
       
        传统规则：每丢弃一个数据包发送一条Source Quench（用户提到的“sent for every discarded packet”）。

    工作流程：

        拥塞节点（路由器/接收端）丢弃数据包后，构造ICMP Type 4（Source Quench）消息。
       
        消息中携带被丢弃包的头部信息（IP+端口），通过ICMP信道回传至发送端。
       
        发送端收到后，按一定比例降低发送速率（如TCP Reno的cwnd减半）。

![](/home/guan/Desktop/计算机网络/Images/4.4/c5f4b689-ae92-4ae2-9813-95ddefa5a467.png)

### 反压

#### **逐跳抑制包（Hop-by-Hop Choke Packets）**

##### **设计背景**

- **长距离链路问题**：端到端RTT可能高达数百ms（如卫星链路），传统Choke Packet反馈延迟导致控制失效。
- **高速链路问题**：100Gbps+链路中，单个RTT内可传输数GB数据，拥塞爆发迅速，需毫秒级响应。

##### **实现机制**

1. **本地拥塞检测**：节点根据队列长度或延迟阈值判断是否拥塞。
2. **生成抑制包**：向直接上游节点发送控制包（包含目标降速比例）。
3. **上游响应**：收到抑制包的节点立即降低发送速率，并可能继续向上游传递抑制信号。
4. **恢复机制**：下游拥塞解除后，发送“恢复包”通知上游逐步提升速率。

![](/home/guan/Desktop/计算机网络/Images/4.4/65ab9788-9096-4b58-86fa-55429a89daac.png)

### 警告位

#### 显式拥塞控制Explicit Congestion Notification (ECN)

1. **报文头标记**ECN通过IP报文头中的1个比特位（实际使用2个比特，由RFC 3168定义）标记拥塞状态。路由器在检测到网络拥塞时（如队列长度超过阈值），会主动设置该比特位，而非直接丢弃报文。
2. **端到端协商**发送端和接收端需通过TCP三次握手协商是否支持ECN（通过**SYN**和**SYN-ACK**报文中的ECN标志位）。仅当双方均支持ECN时，ECN机制才会生效。
3. **ACK反馈机制**若接收端收到带有ECN标记的数据包，会在对应的ACK报文中回显该标记（通过TCP头部的ECN-Echo标志）。发送端通过ACK报文感知拥塞，并触发拥塞控制算法（如降低发送速率），效果等同于检测到丢包。

### ECN的优势



1. **区分拥塞与报文损坏**传统TCP将丢包视为拥塞信号，但在无线网络等易出错的环境中，丢包可能由链路错误导致。ECN可避免误判，提升网络效率。
2. **减少延迟与丢包**路由器通过ECN提前通知拥塞，发送端可主动降速，避免队列溢出导致的丢包和高延迟。这对实时应用（如视频会议）至关重要。
3. **部署灵活性**ECN兼容现有IP和TCP协议，通过重用IP头部的DSCP/ToS字段（RFC 3168），无需修改网络基础设施。在数据中心等可控环境中已广泛应用（如结合AQM算法RED/ECN）。



### ECN的实际应用场景



- **数据中心网络**
   高吞吐、低延迟需求下，ECN与AQM（主动队列管理）结合，显著降低TCP流完成时间（FCT）。
- **5G与边缘计算**
   通过ECN快速反馈拥塞状态，优化资源调度。
- **云计算与虚拟化**
   虚拟交换机支持ECN，提升多租户场景下的公平性。

---

### 随机早期检测

**随机早期检测（Random Early Detection, RED）**
 ◼ **在路由器（交换机）控制拥塞**
 ◼ **结合主机的拥塞窗口**
 ◼ **TCP全局同步问题**

- 流量突发填满队列导致丢包，TCP连接进入慢启动
- 流量骤降导致网络利用率低，连接同时退出慢启动，再次引发突发流量
   ◼ **问题处理——RED**
- 路由器在缓冲区完全填满前随机丢弃数据包

![](/home/guan/Desktop/计算机网络/Images/4.4/c8239741-314d-421c-af7d-35efd208ed99.png)

---

### 公平性

**公平性：通用实现思路**
◼ "公平" 具体指什么？
◼ 路由器将数据包分类为「流」
◼ 假设流是 TCP 连接
◼ 每个流在路由器中拥有独立的 FIFO 队列
◼ 路由器以公平方式调度流
◼ 当链路空闲时，按公平顺序从下一流获取数据包

在网络路由器处理 TCP 流的语境中，**公平性**指为竞争流（competing flows）公平分配带宽，确保没有单一流独占网络资源。

### 公平性的关键原则：

1. **流定义**
   通过五元组（源IP/端口、目的IP/端口、协议）识别独立 TCP 连接，每个连接视为独立流。
2. **隔离队列**
   每个流分配独立缓冲区（FIFO 队列），避免「队头阻塞」（Head-of-Line Blocking）导致的资源抢占。
3. **轮询调度**
   典型实现（如公平队列 FQ）采用循环（Round-Robin）方式：
   ✅ 每个队列按固定权重（如 MTU 大小）服务
   ✅ 避免饥饿现象（长流不阻塞短流）
   ✅ 时间维度上均衡各流吞吐量
4. **带宽公平性指标**
   理想状态下，N 个竞争流应各获得 1/N 的链路容量，例如：
   ⚡ 100Mbps 链路 + 10 个流 → 每个流约 10Mbps

### （重点）Max-Min fairness

![](/home/guan/Desktop/计算机网络/Images/4.4/65359e74-4bb1-4c9b-b1f6-b9cdc355ed5e.png)

![](/home/guan/Desktop/计算机网络/Images/4.4/36284208-1482-4228-9dce-469bf1ab6acb.png)

![](/home/guan/Desktop/计算机网络/Images/4.4/63c9ffa9-edc0-4c90-b1a8-30e1d7d010a3.png)

前提：所有包大小相同

---

### 如果包大小不同

### 核心矛盾

**问题**：如果数据包大小不同，简单的轮询（Round-Robin）会导致不公平。
**举例**：

- 流A：持续发送 **1500字节** 的大包
- 流B：偶尔发送 **100字节** 的小包
  若按包数量轮询，流A实际占用带宽是流B的 **15倍**，显然不公平。

------

### 理想模型：逐比特轮询（Bit-by-bit）

**理论方案**：

1. 将每个数据包拆解成**比特流**
2. 轮流从每个流发送 **1比特**
3. 最终每个流获得的带宽完全均等（如两个流各占50%带宽）

**缺陷**：
❌ 现实中无法切割数据包（网络依赖整包传输）
❌ 数据包有最小单位（如以太网帧必须≥64字节）

------

### 现实方案：公平队列（Fair Queuing）

路由器通过**虚拟时间戳（Virtual Finish Time）**模拟逐比特轮询的效果：

#### 关键步骤

1. **为每个包计算「虚拟完成时间」**
   - 假设当前虚拟时间为 `V(t)`
   - 新到达的包大小为 `L bits`
   - 该包的完成时间 `F = V(t) + L / flow_weight`
     （权重通常按流优先级或约定速率分配）
2. **按「虚拟完成时间」排序发送**
   每次链路空闲时，选择**虚拟完成时间最早**的包发送。

#### 效果类比

- 相当于在虚拟时间轴上，所有流**并行传输比特**
- 实际发送时还原为完整包，但顺序按理想模型的公平性排列

![](/home/guan/Desktop/计算机网络/Images/4.4/1a87e733-0a78-4297-be14-a877a53c5630.png)

### **1. 公平队列 (FQ) 的核心思想**

#### **解决的问题**

传统轮询（Round-Robin）的缺陷：

- **数据包大小不同**时，按“包数量”轮询会导致带宽分配不公平。
  - 例：流A持续发送1500字节大包，流B发送100字节小包 → 流A实际占用带宽是流B的15倍。

#### **FQ 的改进机制**

- **虚拟时间戳 (Virtual Finish Time)**：
  - 为每个数据包计算一个“虚拟完成时间”，基于包的比特长度和链路带宽。
  - 路由器按虚拟完成时间的顺序发送数据包，模拟“逐比特轮询”的公平性。
- **效果**：
  - 长期来看，每个流获得的带宽与其权重（默认均等）成比例，与包大小无关。

------

### **2. 加权公平队列 (WFQ)**

#### **扩展能力**

- 在 FQ 基础上引入 **权重因子**，允许不同流获得差异化的带宽分配。
  - 例：流A权重=2，流B权重=1 → 流A带宽是流B的2倍。

#### **虚拟时间戳计算公式**

- 对于流 ii 的包，其虚拟完成时间 FiFi 为：

  Fi=max⁡(当前虚拟时间,Fi,上一个包)+LiwiFi=max(当前虚拟时间,Fi,上一个包)+wiLi

  - LiLi: 包的比特长度
  - wiwi: 流的权重
  - **调度策略**：始终选择 FiFi 最小的包发送。

#### **应用场景**

- **关键业务隔离**：如 VoIP（权重高）与普通下载（权重低）共存时，保障语音流低延迟。
- **云服务分级**：按客户付费等级分配带宽权重。

------

### **3. 技术演进与部署现状**

#### **80-90年代：FQ/WFQ 未普及的原因**

- **硬件限制**：计算虚拟时间戳需要复杂调度逻辑，早期路由器算力不足。
- **流量特征**：互联网流量以文本和低分辨率图像为主，拥塞问题不显著。
- **替代方案**：采用更粗粒度的隔离（如按 IP 前缀限速），牺牲公平性换取简单性。

#### **现代路由器的 WFQ 实现**

- **默认集成**：几乎所有商用路由器（如 Cisco、Juniper）支持 WFQ 或其变种（如 CBWFQ）。
- **优化变种**：
  - **Deficit Round Robin (DRR)**：通过“信用机制”补偿小包流，降低计算开销。
  - **Hierarchical WFQ**：多级队列嵌套，实现跨网络层级的资源分配（如企业网核心-边缘调度）。

------

### **4. FQ/WFQ 的局限性**

- **计算复杂度**：维护虚拟时间戳和排序需要额外计算资源。
- **突发流量适应性**：短时突发流量可能导致瞬时不公平（需结合令牌桶等整形机制）。
- **加密流量挑战**：若流量加密（如 TLS），路由器无法解析五元组，需依赖外层 IP 头信息（如 DSCP 标记）分类。

---

#### **FQ 的优势**

1. **隔离性 (Isolation)**：作弊的流（如恶意抢占带宽）无法获得额外优势。
2. **带宽分配与 RTT 无关**：流的公平份额不受网络延迟（RTT）影响。
3. **灵活性**：各流可自由选择速率调整策略（如不同拥塞控制算法）。

#### **FQ 的劣势**

1. **复杂度高于 FIFO**：
   - 需维护**每流独立队列**（per-flow queue）
   - 额外的**每包记账开销**（per-packet bookkeeping，如虚拟时间戳计算）

---

![](/home/guan/Desktop/计算机网络/Images/4.4/a6e54e45-193f-4bb5-80d7-3e99c8754083.png)

![](/home/guan/Desktop/计算机网络/Images/4.4/e346026f-f816-478e-9f41-98eb7990190d.png)

---

### **为什么不让路由器直接告诉终端主机该用多少速率？**

#### **基本思路：速率字段（Rate Field）**

1. **数据包携带“速率字段”**：
   - 路由器根据当前网络状态（如链路利用率、队列长度）计算**公平共享速率（fair share rate `f`）**。
   - 将该速率 `f` 写入数据包头部（如 IP 选项或专用字段）。
2. **终端主机响应速率调整**：
   - 接收方将 `f` 通过 ACK 返回发送方（类似 TCP 的窗口反馈机制）。
   - 发送方直接将发送速率（或拥塞窗口）设为 `f`，无需缓慢探测带宽。

#### **潜在优势**

✅ **快速收敛**：

- 传统 TCP 需多次 RTT 探测可用带宽（如 AIMD 机制），而 RCP 直接获取路由器计算的“正确答案”，减少震荡。
  ✅ **全局公平性**：
- 路由器掌握全局信息（如所有流的竞争情况），可更精确分配带宽，避免终端自私行为（如 BBR 流挤占 Cubic 流）。
  ✅ **简化终端逻辑**：
- 终端无需复杂拥塞控制算法（如 CUBIC/BBR），只需服从路由器的速率指令。

------

### **现实挑战与限制**

#### **1. 部署难题**

❌ **路由器计算开销**：

- 需实时计算公平速率 `f`（尤其在大规模网络中），可能增加硬件成本。
  ❌ **协议支持**：
- 需修改 IP/TCP 头部格式以携带速率字段，兼容性差（现有设备可能丢弃未知字段）。

#### **2. 信任与安全**

❌ **恶意路由器攻击**：

- 如果路由器被入侵，伪造低速率 `f` 可故意限制某些流（需加密验证机制）。
  ❌ **终端合规性**：
- 自私终端可能忽略 `f` 并继续超速发送（需强制速率 policing，如令牌桶）。

#### **3. 动态适应性**

❌ **突发流量场景**：

- 路由器计算的 `f` 可能滞后于瞬时流量变化（如短时突发导致队列堆积）。
  ❌ **异构网络环境**：
- 在复杂路径（如多运营商跨网）中，不同路由器可能给出冲突的 `f` 值。

------

### **Rate Control Protocol (RCP) 的实践**

#### **核心设计（Dukkipati et al., 2007）**

- **速率计算**：
  路由器基于 **链路剩余带宽** 和 **当前流数量** 计算 `f`，公式示例：

  f=剩余带宽活跃流数量+α⋅队列补偿项f=活跃流数量剩余带宽+α⋅队列补偿项

- **反馈机制**：
  数据包在传输路径中被路由器逐跳更新 `f`，终端最终取最小值作为发送速率。

#### **性能对比（RCP vs TCP）**

| 指标         | RCP              | 传统 TCP (如 CUBIC)           |
| ------------ | ---------------- | ----------------------------- |
| **收敛速度** | ⚡ 1-2 RTT 内收敛 | 🐢 需多个 RTT 探测带宽         |
| **公平性**   | 🌍 全局最优分配   | 🔄 依赖终端算法，易受 RTT 影响 |
| **部署成本** | 🔧 需路由器升级   | ✅ 即插即用                    |

------

### **为什么 RCP 未被广泛采用？**

1. **增量部署困难**：
   - 需全网路由器支持 RCP，而 TCP 只需终端升级。
2. **与现有协议冲突**：
   - 现代 TCP 变种（如 BBR）已通过端到端优化实现低延迟+高吞吐，削弱了 RCP 的优势。
3. **控制权争议**：
   - 互联网设计哲学倾向于“终端智能+网络简单”，而 RCP 将核心逻辑放在网络中，违背这一原则。

------

### **未来方向**

- **混合方案**：
  结合路由器显式反馈（如 RCP）与终端自主控制（如 BBR），例如 **Explicit Congestion Notification (ECN++)**。
- **数据中心应用**：
  在可控环境（如企业内网/云数据中心）中试点 RCP，因其设备统一、易管理。